{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "## **模型求解算法**\n",
    "\n",
    "正则化可以有效防止过拟合, 增强模型的泛化能力, 这时模型的评估策略就是让结构化的经验风险最小, 即增加正则化项的损失函数最小, 称之为**结构风险最小化**\n",
    "\n",
    "$$\n",
    "\\min \\frac{1}{n} \\left( \\sum_{i=1}^{n} L(y_i, f(x_i)) + \\lambda J(\\theta) \\right)\n",
    "$$\n",
    "\n",
    "其中, $L(y_i, f(x_i))$ 是损失函数, $J(\\theta)$ 是正则化项, $\\lambda$ 是正则化参数, $\\theta$ 是模型参数\n",
    "\n",
    "这其实就是求解一个**最优化问题**, 带入训练集的所有数据(xi, yi), 要求最小值的目标函数就是关于$\\theta$的函数"
   ],
   "id": "27f4a15e3f7e799e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **解析法**\n",
    "\n",
    "如果损失函数的最小值可以通过数学公式严格推导得到一个解析解, 那么就直接得到了最优模型的所有参数, 这种方法叫做解析法\n",
    "\n",
    "本质上就是求损失函数的最值问题, 对损失函数求导使导数为0, 找到最小值, 问题在于参数的维度一般很高计算会过于复杂, 解析法一般用于维度较小的问题, 求解简单的模型都要进行大量运算条件较为苛刻\n",
    "\n",
    "具有以下特点:\n",
    "- 目标函数必须可导, 且导数方程必须有解析解\n",
    "- 计算直接且精准\n",
    "- 适用条件严苛, 特征维度较大时矩阵求逆计算复杂度极高\n",
    "\n",
    "应用实例: 线性回归问题(最小二乘法), lasso回归"
   ],
   "id": "20580246d11c5d7f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
